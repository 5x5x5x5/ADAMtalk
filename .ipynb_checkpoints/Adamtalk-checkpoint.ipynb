{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next Generation Genomic Analysis with Spark and ADAM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data deluge from Next Gen Sequencing\n",
    "\n",
    "- 1 Human Genome = 3.2 billion base pairs (bps)\n",
    "- Assembled from fragments of 100 to 250bps\n",
    "- 60X replication of genome needed for statistical soundness\n",
    "- so 1.4 billion fragments gives you ~200GB of data\n",
    "\n",
    "### All that for about $1000\n",
    "\n",
    "- Then, alignment against a reference (for humans and a few model organisms)\n",
    "- Pipelines take that 200GB input >> 1 - 3 GB output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But, what does it all mean?\n",
    "\n",
    "- This is the question scientists would like to spend time on.\n",
    "- But current pipelines can take days.\n",
    "- There is a need to seperate methods from computation.\n",
    "- Still the early days of genomic sciences.\n",
    "\n",
    "### Many more sequencing opportunities\n",
    "\n",
    "- De novo assembly of new species\n",
    "- \\*biome\n",
    "- [RNAseq](http://rnaseq.uoregon.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Current pipeline\n",
    "- Many command line tools chained together.\n",
    "- Intermediate files written to disk.\n",
    "\n",
    "### [Genome Analysis Tool Kit](https://www.broadinstitute.org/gatk/)\n",
    "\n",
    "<img src=img/gatk.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next Gen Analysis for Next Gen Sequencing \n",
    "\n",
    "\n",
    "[ADAM](https://github.com/bigdatagenomics) applies some good old fashioned computer science to speed up this process.\n",
    "- [Amplab goals](https://github.com/massie/nci_design/blob/master/adam_design.pdf) for the ADAM project [Overview paper](http://www.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-207.pdf)\n",
    "  - from custom file formats to schema\n",
    "  - from flat files and RDMS to columnar storage systems\n",
    "  - move to in-memory computation\n",
    "  - easy to do distributed computation\n",
    "\n",
    "### Latest paper\n",
    " * [Rethinking Data Intensive Science Using Scalable Analytics Systems](http://www.istc-cc.cmu.edu/publications/papers/2015/adam.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Columnar Storage with Apache Parquet](http://www.slideshare.net/cloudera/hadoop-summit-36479635)\n",
    "\n",
    "<img src=img/columnar.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom File Formats to Schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributed In-Memory Computation with [Apache Spark](http://spark.apache.org/)\n",
    "\n",
    "<img src=img/SparkVsHadoop.jpg>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src=img/spark-stack.png>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
