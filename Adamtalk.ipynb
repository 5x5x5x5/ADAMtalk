{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next Generation Genomic Analysis with Spark and ADAM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data deluge from Next Gen Sequencing\n",
    "\n",
    "- 1 Human Genome = 3.2 billion base pairs (bps)\n",
    "- Assembled from fragments of 100 to 250bps\n",
    "- 60X replication of genome needed for statistical soundness\n",
    "- so 1.4 billion fragments gives you ~200GB of data\n",
    "\n",
    "### All that for about $1000\n",
    "\n",
    "- Then, alignment against a reference (for humans and a few model organisms)\n",
    "- Pipelines take that 200GB input >> 1 - 3 GB output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### But, what does it all mean?\n",
    "\n",
    "- This is the question scientists would like to spend time on.\n",
    "- But current pipelines can take days.\n",
    "- There is a need to seperate methods from computation.\n",
    "- Still the early days of genomic sciences.\n",
    "\n",
    "### Many more sequencing opportunities\n",
    "\n",
    "- De novo assembly of new species\n",
    "- \\*biome\n",
    "- [RNAseq](http://rnaseq.uoregon.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Current pipeline\n",
    "- Many command line tools chained together.\n",
    "- Intermediate files written to disk.\n",
    "\n",
    "### [Genome Analysis Tool Kit](https://www.broadinstitute.org/gatk/)\n",
    "\n",
    "<img src=img/gatk.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next Gen Analysis for Next Gen Sequencing \n",
    "\n",
    "\n",
    "[ADAM](https://github.com/bigdatagenomics) applies some good old fashioned computer science to speed up the process.\n",
    "- [Amplab goals](https://github.com/massie/nci_design/blob/master/adam_design.pdf) for the ADAM project - [Overview paper](http://www.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-207.pdf)\n",
    "  - from custom file formats to schema\n",
    "  - from flat files and RDMS to columnar storage systems\n",
    "  - move to in-memory computation\n",
    "  - easy to do distributed computation\n",
    "\n",
    "### Latest paper\n",
    " * [Rethinking Data Intensive Science Using Scalable Analytics Systems](http://www.istc-cc.cmu.edu/publications/papers/2015/adam.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Columnar Storage with Apache Parquet](http://www.slideshare.net/cloudera/hadoop-summit-36479635)\n",
    "\n",
    "<img src=img/columnar.jpg>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom File Formats to Schema\n",
    "and back again with [Apache Avro](https://en.wikipedia.org/wiki/Apache_Avro)\n",
    "\n",
    "<TABLE>\n",
    "<CAPTION></CAPTION>\n",
    "\n",
    "<TR>\n",
    "<TD>  <img src=img/nestedlists.png>  </TD>\n",
    "<TD>  <img src=img/rowvscolumn.png> </TD>\n",
    "\n",
    "</TR>\n",
    "</TABLE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distributed In-Memory Computation with [Apache Spark](http://spark.apache.org/)\n",
    "\n",
    "<img src=img/SparkVsHadoop.jpg>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sweet Tools Available in Spark Ecosystem\n",
    "So the scientists can finally get back to the important bits.\n",
    "\n",
    "<img src=img/spark-stack.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### They say it better than I ever could\n",
    "\n",
    "<TABLE>\n",
    "<CAPTION></CAPTION>\n",
    "\n",
    "<TR>\n",
    "<TD> <iframe width=\"280\" height=\"160\" src=\"https://www.youtube.com/embed/ctLyjYw0BOg\" frameborder=\"0\" allowfullscreen></iframe> </TD>\n",
    "<TD>  <iframe width=\"280\" height=\"160\" src=\"https://www.youtube.com/embed/axLEBM_PZeI\" frameborder=\"0\" allowfullscreen></iframe> </TD>\n",
    "\n",
    "</TR>\n",
    "</TABLE>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## To continue\n",
    "\n",
    "Sign up for a [cloud account](https://en.wikipedia.org/wiki/Cloud_computing_comparison):\n",
    "\n",
    "- Amazon has plenty of walkthroughs and makes it easy to start down their primrose path, but why not listen to [this guy](http://www.crmarsh.com/aws/)\n",
    "- [Microsoft Azure](https://azure.microsoft.com/en-us/pricing/free-trial/) will surely be the darling of enterprise.\n",
    "- Or stick with the [propeller heads](https://cloud.google.com/)\n",
    "\n",
    "\n",
    "\n",
    "Here is a [script to install ADAM](https://github.com/5x5x5x5/ADAMstartup.git) for further exploration (test run on Ubuntu 14.04 LTS server)\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/5x5x5x5/ADAMstartup.git\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
